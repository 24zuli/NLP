{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24zuli/NLP/blob/main/Tutorial1_DL4NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2OiGvflVwnB"
      },
      "source": [
        "## **N-Gram Language Model Tutorial**\n",
        "### This Jupyter Notebook will guide you through the basics of N-Gram language models using Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "20xATuL3V_Qq"
      },
      "outputs": [],
      "source": [
        "# Importing Required Libraries\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import math\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6ykvDQNV-Nw"
      },
      "source": [
        "#### **1. N-Gram**\n",
        "\n",
        "#### What is an N-Gram?\n",
        "\n",
        "An N-Gram is a contiguous sequence of N items (words, characters, etc.) from a given text.\n",
        "\n",
        "For example, in the sentence \"I love machine learning\", the 2-grams (bigrams) are:\n",
        "\n",
        "[\"I love\", \"love machine\", \"machine learning\"]\n",
        "\n",
        "#### N-Gram Probability Equation\n",
        "The probability of a word \\( w_n \\) given its history \\( h \\) in an n-gram model is:\n",
        "$$\n",
        "P(w_n \\mid h) = \\frac{C(h, w_n)}{\\sum_{w'} C(h, w')}\n",
        "$$\n",
        "Where:\n",
        "- \\( C(h, w_n) \\): Count of occurrences of \\( h \\) followed by \\( w_n \\)\n",
        "- \\( h \\): Context (history of n-1 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ONUihztsV6Qk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_ngrams(text, n):\n",
        "    \"\"\"\n",
        "    Generate n-grams (character-level) from a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Input text\n",
        "    n (int): Size of the n-grams\n",
        "\n",
        "    Returns:\n",
        "    list: A list of n-grams as tuples\n",
        "    \"\"\"\n",
        "    # Added padding with '#' characters to handle the start of sequences\n",
        "    padded_text = '#' * (n-1) + text\n",
        "    ngrams = []\n",
        "    for i in range(len(padded_text) - n + 1):\n",
        "        ngram = tuple(padded_text[i:i+n])\n",
        "        ngrams.append(ngram)\n",
        "    return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zvT0qMoWawC",
        "outputId": "b8206b14-2159-420f-8b08-b0f9446ae47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character-Level Bigrams: [('#', 'h'), ('h', 'e'), ('e', 'l'), ('l', 'l'), ('l', 'o'), ('o', ' '), (' ', 'w'), ('w', 'o'), ('o', 'r'), ('r', 'l'), ('l', 'd')]\n"
          ]
        }
      ],
      "source": [
        "# Example Text\n",
        "text = \"hello world\"\n",
        "\n",
        "# Generate and display bigrams (2-grams)\n",
        "bigrams = generate_ngrams(text, 2)\n",
        "print(\"Character-Level Bigrams:\", bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OMWOU8D9bj-b"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(corpus, n):\n",
        "    \"\"\"\n",
        "    Build an n-gram language model from the corpus.\n",
        "\n",
        "    Parameters:\n",
        "    corpus (str): Text corpus for building the model\n",
        "    n (int): Size of the n-grams\n",
        "\n",
        "    Returns:\n",
        "    dict: A probability distribution for each context\n",
        "    \"\"\"\n",
        "    # Initialize the model\n",
        "    model = defaultdict(Counter)\n",
        "\n",
        "    # Generate n-grams\n",
        "    ngrams = generate_ngrams(corpus, n)\n",
        "\n",
        "    # Build the model\n",
        "    for ngram in ngrams:\n",
        "        context = ngram[:-1]  # all but the last character\n",
        "        char = ngram[-1]      # the last character\n",
        "        model[context][char] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for context in model:\n",
        "        total_count = sum(model[context].values())\n",
        "        for char in model[context]:\n",
        "            model[context][char] = model[context][char] / total_count\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK7mI5iyWipq"
      },
      "source": [
        "#### **2. Smoothing**\n",
        "\n",
        "Smoothing assigns a small non-zero probability to unseen n-grams.\n",
        "\n",
        "#### Smoothing Equation\n",
        "With smoothing, the probability becomes:\n",
        "$$\n",
        "P(w_n \\mid h) = \\frac{C(h, w_n) + \\alpha}{\\sum_{w'} C(h, w') + \\alpha \\times |V|}\n",
        "$$\n",
        "Where:\n",
        "- $\\alpha $: Smoothing parameter (default is 1)\n",
        "- \\( |V| \\): Vocabulary size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rak99gJ7WasJ"
      },
      "outputs": [],
      "source": [
        "def add_smoothing(model, vocabulary_size, alpha=1.0):\n",
        "    \"\"\"\n",
        "    Apply smoothing to an n-gram model.\n",
        "\n",
        "    Parameters:\n",
        "    model (defaultdict): N-gram model.\n",
        "    vocabulary_size (int): Total number of unique characters in the vocabulary.\n",
        "    alpha (float): Smoothing parameter (default is 1.0).\n",
        "\n",
        "    Returns:\n",
        "    defaultdict: Smoothed n-gram model.\n",
        "    \"\"\"\n",
        "    smoothed_model = defaultdict(Counter)\n",
        "    for prefix, char_counts in model.items():\n",
        "        total_count = sum(char_counts.values()) + alpha * vocabulary_size\n",
        "        for char in char_counts:\n",
        "            smoothed_model[prefix][char] = (char_counts[char] + alpha) / total_count\n",
        "        for char in range(vocabulary_size):\n",
        "            if char not in char_counts:\n",
        "                smoothed_model[prefix][char] = alpha / total_count\n",
        "    return smoothed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUUvZwVYW1-F"
      },
      "source": [
        "#### **3. Generating Text Using the N-Gram Model**\n",
        "\n",
        "To generate text, we sample from the model using the probabilities of the next word given the current context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_G12hnRLWapc"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, n, start_text, length=100):\n",
        "    \"\"\"\n",
        "    Generate text using the n-gram model.\n",
        "\n",
        "    Parameters:\n",
        "    model (dict): Trained n-gram model\n",
        "    n (int): Size of the n-grams\n",
        "    start_text (str): Initial text to start generation\n",
        "    length (int): Number of characters to generate\n",
        "\n",
        "    Returns:\n",
        "    str: Generated text\n",
        "    \"\"\"\n",
        "    # Initialize with start text\n",
        "    current_text = list(start_text)\n",
        "\n",
        "    # Generate characters\n",
        "    for _ in range(length):\n",
        "        # Get the current context\n",
        "        context = tuple(current_text[-(n-1):]) if len(current_text) >= n-1 else tuple('#' * (n-1 - len(current_text)) + ''.join(current_text))\n",
        "\n",
        "        # If context not in model, break\n",
        "        if context not in model:\n",
        "            break\n",
        "\n",
        "        # Get probability distribution for next character\n",
        "        char_dist = model[context]\n",
        "\n",
        "        # Sample next character\n",
        "        chars, probs = zip(*char_dist.items())\n",
        "        next_char = random.choices(chars, weights=probs)[0]\n",
        "\n",
        "        # Append to generated text\n",
        "        current_text.append(next_char)\n",
        "\n",
        "    return ''.join(current_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLoX7FkBWag1",
        "outputId": "f17ed5bc-344a-40e9-e6fb-2eba8bb98906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: heldello wod\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "text = \"hello world this is a sample text for testing the n-gram model\"\n",
        "\n",
        "# Build a bigram model\n",
        "bigram_model = build_ngram_model(text, 2)\n",
        "\n",
        "# Generate text\n",
        "generated = generate_text(bigram_model, 2, \"he\", 10)\n",
        "print(f\"Generated text: {generated}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNyoSdyXGSE"
      },
      "source": [
        "#### **4. Evaluating the Language Model**\n",
        "\n",
        "#### **Perplexity**\n",
        "\n",
        "Perplexity is a common metric for evaluating language models. Lower perplexity indicates a better model.\n",
        "\n",
        "#### Perplexity Equation\n",
        "Perplexity measures how well a language model predicts a test dataset:\n",
        "$$\n",
        "PP(W) = 2^{-\\frac{1}{N} \\sum_{i=1}^{N} \\log_2 P(w_i \\mid h_i)}\n",
        "$$\n",
        "Where:\n",
        "- \\( W \\): Sequence of words\n",
        "- \\( N \\): Total number of words in the sequence\n",
        "- $ P(w_i \\mid h_i) $: Probability of word $w_i$ given its history $ h_i $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QUqppwpAXFuH"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, n, test_text):\n",
        "    \"\"\"\n",
        "    Calculate perplexity of the model on test text.\n",
        "\n",
        "    Parameters:\n",
        "    model (dict): Trained n-gram model\n",
        "    n (int): Size of the n-grams\n",
        "    test_text (str): Text to evaluate on\n",
        "\n",
        "    Returns:\n",
        "    float: Perplexity score\n",
        "    \"\"\"\n",
        "    ngrams = generate_ngrams(test_text, n)\n",
        "    log_prob = 0\n",
        "    total_ngrams = len(ngrams)\n",
        "\n",
        "    for ngram in ngrams:\n",
        "        context = ngram[:-1]\n",
        "        char = ngram[-1]\n",
        "\n",
        "        if context in model and char in model[context]:\n",
        "            prob = model[context][char]\n",
        "            log_prob += -1 * math.log2(prob)\n",
        "        else:\n",
        "            return float('inf')  # Return infinity for unseen n-grams\n",
        "\n",
        "    return 2 ** (log_prob / total_ngrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's create a more substantial training corpus\n",
        "training_corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "She sells seashells by the seashore.\n",
        "How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
        "To be or not to be, that is the question.\n",
        "All that glitters is not gold.\n",
        "A journey of a thousand miles begins with a single step.\n",
        "Actions speak louder than words.\n",
        "Beauty is in the eye of the beholder.\n",
        "Every cloud has a silver lining.\n",
        "Fortune favors the bold and brave.\n",
        "Life is like a box of chocolates.\n",
        "The early bird catches the worm.\n",
        "Where there's smoke, there's fire.\n",
        "Time heals all wounds and teaches all things.\n",
        "Knowledge is power, and power corrupts.\n",
        "Practice makes perfect, but nobody's perfect.\n",
        "The pen is mightier than the sword.\n",
        "When in Rome, do as the Romans do.\n",
        "A picture is worth a thousand words.\n",
        "Better late than never, but never late is better.\n",
        "Experience is the best teacher of all things.\n",
        "Laughter is the best medicine for the soul.\n",
        "Music soothes the savage beast within us.\n",
        "Nothing ventured, nothing gained in life.\n",
        "The grass is always greener on the other side.\n",
        "\"\"\"\n",
        "\n",
        "# Clean the corpus\n",
        "training_corpus = ''.join(c.lower() for c in training_corpus if c.isalnum() or c.isspace())"
      ],
      "metadata": {
        "id": "VH5m9Bkscnae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "qZZ5c029iDEJ",
        "outputId": "2b56fe6a-7c53-4676-898a-e22c45b70f93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nthe quick brown fox jumps over the lazy dog\\nshe sells seashells by the seashore\\nhow much wood would a woodchuck chuck if a woodchuck could chuck wood\\nto be or not to be that is the question\\nall that glitters is not gold\\na journey of a thousand miles begins with a single step\\nactions speak louder than words\\nbeauty is in the eye of the beholder\\nevery cloud has a silver lining\\nfortune favors the bold and brave\\nlife is like a box of chocolates\\nthe early bird catches the worm\\nwhere theres smoke theres fire\\ntime heals all wounds and teaches all things\\nknowledge is power and power corrupts\\npractice makes perfect but nobodys perfect\\nthe pen is mightier than the sword\\nwhen in rome do as the romans do\\na picture is worth a thousand words\\nbetter late than never but never late is better\\nexperience is the best teacher of all things\\nlaughter is the best medicine for the soul\\nmusic soothes the savage beast within us\\nnothing ventured nothing gained in life\\nthe grass is always greener on the other side\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build models of different orders\n",
        "def build_models(corpus):\n",
        "    models = {}\n",
        "    for n in [2, 3, 4]:  # bigram, trigram, and 4-gram models\n",
        "        models[n] = build_ngram_model(corpus, n)\n",
        "    return models\n",
        "\n",
        "# Build the models\n",
        "models = build_models(training_corpus)"
      ],
      "metadata": {
        "id": "MF8RoYtDUVCj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate samples and calculate perplexity\n",
        "def evaluate_samples(models, num_samples=10, sample_length=40):\n",
        "    \"\"\"\n",
        "    Evaluates multiple n-gram language models by generating text samples and calculating their perplexity scores.\n",
        "\n",
        "    This function:\n",
        "    1. Takes different n-gram models (e.g., bigram, trigram, 4-gram)\n",
        "    2. For each model:\n",
        "       - Generates multiple text samples\n",
        "       - Calculates perplexity for each sample\n",
        "       - Computes average perplexity across all samples\n",
        "    3. Stores and returns all results for comparison\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    models : dict\n",
        "        Dictionary where keys are n-gram sizes (e.g., 2 for bigram)\n",
        "        and values are the trained n-gram models\n",
        "\n",
        "    num_samples : int, optional (default=5)\n",
        "        Number of text samples to generate for each model\n",
        "\n",
        "    sample_length : int, optional (default=30)\n",
        "        Length of each generated text sample in characters\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        A dictionary where:\n",
        "        - Keys are n-gram sizes (2, 3, 4, etc.)\n",
        "        - Values are lists of dictionaries containing:\n",
        "          {'text': generated_text, 'perplexity': perplexity_score}\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    # Example output structure:\n",
        "    {\n",
        "        2: [  # Results for bigram model\n",
        "            {'text': 'hello world', 'perplexity': 10.5},\n",
        "            {'text': 'sample text', 'perplexity': 12.3},\n",
        "            # ... more samples\n",
        "        ],\n",
        "        3: [  # Results for trigram model\n",
        "            {'text': 'another example', 'perplexity': 8.7},\n",
        "            # ... more samples\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    for n, model in models.items():\n",
        "        print(f\"\\n=== {n}-gram Model Evaluation ===\")\n",
        "\n",
        "        # Generate multiple samples\n",
        "        start_text = training_corpus[:n-1]\n",
        "        for i in range(num_samples):\n",
        "            # Generate sample\n",
        "            generated = generate_text(model, n, start_text, sample_length)\n",
        "\n",
        "            # Calculate perplexity\n",
        "            perplexity = calculate_perplexity(model, n, generated)\n",
        "\n",
        "            print(f\"\\nSample {i+1}:\")\n",
        "            print(f\"Text: {generated}\")\n",
        "            print(f\"Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "            results[n].append({\n",
        "                'text': generated,\n",
        "                'perplexity': perplexity\n",
        "            })\n",
        "\n",
        "        # Calculate average perplexity for this n-gram model\n",
        "        avg_perplexity = sum(sample['perplexity'] for sample in results[n]) / len(results[n])\n",
        "        print(f\"\\nAverage Perplexity for {n}-gram model: {avg_perplexity:.2f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "13kHhr1ccIQh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate samples\n",
        "results = evaluate_samples(models)\n",
        "\n",
        "# Calculate statistics for each model\n",
        "print(\"\\n=== Overall Statistics ===\")\n",
        "for n in models.keys():\n",
        "    perplexities = [sample['perplexity'] for sample in results[n]]\n",
        "    min_perp = min(perplexities)\n",
        "    max_perp = max(perplexities)\n",
        "    avg_perp = sum(perplexities) / len(perplexities)\n",
        "\n",
        "    print(f\"\\n{n}-gram Model Statistics:\")\n",
        "    print(f\"Minimum Perplexity: {min_perp:.2f}\")\n",
        "    print(f\"Maximum Perplexity: {max_perp:.2f}\")\n",
        "    print(f\"Average Perplexity: {avg_perp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy_JvJ8scaAU",
        "outputId": "f536c899-974f-4318-a565-e64812366813"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 2-gram Model Evaluation ===\n",
            "\n",
            "Sample 1:\n",
            "Text: \n",
            "the s thule\n",
            "eck asere s doouloucothousan\n",
            "Perplexity: 7.00\n",
            "\n",
            "Sample 2:\n",
            "Text: \n",
            "aste\n",
            "er cthimur athe he be inge ingsans \n",
            "Perplexity: 6.32\n",
            "\n",
            "Sample 3:\n",
            "Text: \n",
            "fealas ckere wocthe wothetheve\n",
            "lis s\n",
            "e t\n",
            "Perplexity: 5.80\n",
            "\n",
            "Sample 4:\n",
            "Text: \n",
            "aurs\n",
            "thes\n",
            "boraver on or as sollllor thul\n",
            "Perplexity: 7.16\n",
            "\n",
            "Sample 5:\n",
            "Text: \n",
            "le ter s\n",
            "lleat inor gs berye alik wec tu\n",
            "Perplexity: 8.05\n",
            "\n",
            "Sample 6:\n",
            "Text: \n",
            "thodye idserors tud ne beatha orn cldir \n",
            "Perplexity: 8.62\n",
            "\n",
            "Sample 7:\n",
            "Text: \n",
            "a qug hesthtodge ox gr\n",
            "feveangher be ld \n",
            "Perplexity: 8.12\n",
            "\n",
            "Sample 8:\n",
            "Text: \n",
            "mathuckenorss e boo s sther a swoowola w\n",
            "Perplexity: 7.75\n",
            "\n",
            "Sample 9:\n",
            "Text: \n",
            "ereththes\n",
            "ld buld an s chuthorthazy is s\n",
            "Perplexity: 6.20\n",
            "\n",
            "Sample 10:\n",
            "Text: \n",
            "litthime dovandomurthe thingan thuct jud\n",
            "Perplexity: 7.74\n",
            "\n",
            "Average Perplexity for 2-gram model: 7.28\n",
            "\n",
            "=== 3-gram Model Evaluation ===\n",
            "\n",
            "Sample 1:\n",
            "Text: \n",
            "therfe swounever of chuck cater of chuck \n",
            "Perplexity: 2.32\n",
            "\n",
            "Sample 2:\n",
            "Text: \n",
            "timed ne of a spence early othe woodche t\n",
            "Perplexity: 2.77\n",
            "\n",
            "Sample 3:\n",
            "Text: \n",
            "th a sells better thes per over cate he s\n",
            "Perplexity: 2.80\n",
            "\n",
            "Sample 4:\n",
            "Text: \n",
            "the quict nobolate the soulde\n",
            "lins a witt\n",
            "Perplexity: 2.76\n",
            "\n",
            "Sample 5:\n",
            "Text: \n",
            "thin row mighte of chuck woodchuck is not\n",
            "Perplexity: 2.09\n",
            "\n",
            "Sample 6:\n",
            "Text: \n",
            "the a words\n",
            "ling ver ther the dog\n",
            "fox jum\n",
            "Perplexity: 2.19\n",
            "\n",
            "Sample 7:\n",
            "Text: \n",
            "thinever is thins do\n",
            "a by of to a wousavo\n",
            "Perplexity: 2.79\n",
            "\n",
            "Sample 8:\n",
            "Text: \n",
            "tions woreence a powle in thes ans gracti\n",
            "Perplexity: 3.07\n",
            "\n",
            "Sample 9:\n",
            "Text: \n",
            "thinineye firds is pow medicinever the is\n",
            "Perplexity: 2.52\n",
            "\n",
            "Sample 10:\n",
            "Text: \n",
            "thould woud word words\n",
            "the beginever the \n",
            "Perplexity: 2.47\n",
            "\n",
            "Average Perplexity for 3-gram model: 2.58\n",
            "\n",
            "=== 4-gram Model Evaluation ===\n",
            "\n",
            "Sample 1:\n",
            "Text: \n",
            "the be of a silver corrupts\n",
            "practice makes\n",
            "Perplexity: 1.37\n",
            "\n",
            "Sample 2:\n",
            "Text: \n",
            "ther is power lazy dog\n",
            "she eye or not glit\n",
            "Perplexity: 1.62\n",
            "\n",
            "Sample 3:\n",
            "Text: \n",
            "the quick brown fox of chuck wood\n",
            "to be th\n",
            "Perplexity: 1.40\n",
            "\n",
            "Sample 4:\n",
            "Text: \n",
            "the best medicine for the step\n",
            "actice is b\n",
            "Perplexity: 1.45\n",
            "\n",
            "Sample 5:\n",
            "Text: \n",
            "the or ther and miles fire\n",
            "how much wounds\n",
            "Perplexity: 1.52\n",
            "\n",
            "Sample 6:\n",
            "Text: \n",
            "the greener the savage box jumps over the \n",
            "Perplexity: 1.42\n",
            "\n",
            "Sample 7:\n",
            "Text: \n",
            "the box of than nevery clouder\n",
            "experfect b\n",
            "Perplexity: 1.39\n",
            "\n",
            "Sample 8:\n",
            "Text: \n",
            "the step\n",
            "actice is thes fire\n",
            "time dog\n",
            "shel\n",
            "Perplexity: 1.43\n",
            "\n",
            "Sample 9:\n",
            "Text: \n",
            "ther than wounds all there theres fire\n",
            "how\n",
            "Perplexity: 1.66\n",
            "\n",
            "Sample 10:\n",
            "Text: \n",
            "the question\n",
            "all the seashore\n",
            "time do\n",
            "a pi\n",
            "Perplexity: 1.37\n",
            "\n",
            "Average Perplexity for 4-gram model: 1.46\n",
            "\n",
            "=== Overall Statistics ===\n",
            "\n",
            "2-gram Model Statistics:\n",
            "Minimum Perplexity: 5.80\n",
            "Maximum Perplexity: 8.62\n",
            "Average Perplexity: 7.28\n",
            "\n",
            "3-gram Model Statistics:\n",
            "Minimum Perplexity: 2.09\n",
            "Maximum Perplexity: 3.07\n",
            "Average Perplexity: 2.58\n",
            "\n",
            "4-gram Model Statistics:\n",
            "Minimum Perplexity: 1.37\n",
            "Maximum Perplexity: 1.66\n",
            "Average Perplexity: 1.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAd_fFOKLogh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}